{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf3f023",
   "metadata": {},
   "source": [
    "# IMPORTATION DES BIBLIOTHEQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Télécharger les ressources nécessaires de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329dbcea",
   "metadata": {},
   "source": [
    "# DEFINITION DES DICTIONNAIRE NECESSAIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc54731",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_medical={\n",
    "    \"Ttt\": \"Traitement\",\n",
    "    'Pat': 'Patient',\n",
    "}\n",
    "terme_medicals = {\n",
    "    \"corticoïdes\" : \"glucocorticoides\",\n",
    "    \"azithromycine\" : \"azithromycine\",\n",
    "}\n",
    "expressions_composes = {\n",
    "    \"++fébrile\" : \"hyperthermique\",\n",
    "}\n",
    "abreviations = {\n",
    "    \"IV\" : \"intraveineux\",\n",
    "    \"COVID-19\" : \"coronavirus\",\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c4113",
   "metadata": {},
   "source": [
    "# NETTOYAGE DU TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient  admis le  pour coronavirus svre\n",
      "CRP  N5 - Fivre  39.2C\n",
      "Traitement par glucocorticoides intraveineux  azithromycine  \n",
      "Attention allergie  la pnicilline\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def nettoyer_texte(texte):\n",
    "\n",
    "\n",
    "    for items,abreviation in abreviations.items():\n",
    "        texte = texte.replace(items, abreviation)\n",
    "    for items,terme_medical in terme_medicals.items():\n",
    "        texte = texte.replace(items, terme_medical)\n",
    "    for items,expressions_compose in expressions_composes.items():\n",
    "        texte = texte.replace(items, expressions_compose)\n",
    "    \n",
    "\n",
    "    # Supprimer les dates (format JJ/MM/AA ou JJ/MM/AAAA)\n",
    "    texte = re.sub(r'\\d{2}/\\d{2}/\\d{2,4}', '', texte)\n",
    "\n",
    "    # remove punctuation except for . between numbers\n",
    "    texte = re.sub(r'(?<!\\d)\\.(?!\\d)', '', texte)\n",
    "    \n",
    "    # Supprimer les valeurs numériques avec unités (ex: \"125mg/L\", \"500mg/J\"), mais conserver les nombres sans unités\n",
    "    texte = re.sub(r'\\d+(\\.\\d+)?[a-zA-Z/]+', '', texte)\n",
    "    \n",
    "    # Supprimer les caractères spéciaux (ex: \"#\", \"°\",'º',etc.)\n",
    "    texte = re.sub(r'[^a-zA-Z0-9\\s.,-]', '', texte)    \n",
    "\n",
    "    for error, signification in error_medical.items():\n",
    "        texte = texte.replace(error, signification)\n",
    "    \n",
    "    return texte.strip()\n",
    "\n",
    "# Exemple\n",
    "texte_medical = \"\"\"\n",
    "Pat. 45ans admis le 12/03/25 pour COVID-19 sévère.\n",
    "CRP: 125mg/L (N<5) - Fièvre à 39.2°C.\n",
    "Ttt par corticoïdes IV + azithromycine 500mg/J. 500mg\n",
    "#Attention: allergie à la pénicilline!\n",
    "\"\"\"\n",
    "texte_nettoye = nettoyer_texte(texte_medical)\n",
    "print(texte_nettoye)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38642202",
   "metadata": {},
   "source": [
    "# CONSERVCATION DES DOSES ET DES MOTS COMPOSÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4a09a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('125', 'mg', '/', 'L'), ('500', 'mg', '/', 'J'), ('125', 'mg'), ('500', 'mg'), ('500', 'mg'), 'COVID-19']\n"
     ]
    }
   ],
   "source": [
    "def conserve_important_words(texte):\n",
    "    # Conserver les concepts composés\n",
    "    texte = re.sub(r'(\\w+-\\w+)', r' \\1 ', texte)\n",
    "    \n",
    "    # Séparer les doses\n",
    "    texte_test = re.sub(r'(\\d+)(mg|g|ml|L|J|j|l)(/|\\s)?(mg|min|g|ml|L|J|j|l)?', r\"[['\\1','\\2','\\3','\\4']]\", texte)\n",
    "    texte_test1 = re.sub(r'(\\d+)(mg|g|ml|L|J|j|l)', r\"[['\\1','\\2']]\", texte)\n",
    "    \n",
    "    # get the dosez with uniut/unit and unite\n",
    "    doses = re.findall(r'\\[\\[\\'(\\d+)\\',\\'([a-zA-Z]+)\\',\\'([/ ]?)\\',\\'([a-zA-Z]+)\\'\\]\\]', texte_test)\n",
    "\n",
    "    # get doses with unite (mg|g|ml|L|J|j|l)\n",
    "    doses =doses + re.findall(r'\\[\\[\\'(\\d+)\\',\\'([a-zA-Z]+)\\'\\]\\]', texte_test1)\n",
    "\n",
    "\n",
    "    # get concepts composés\n",
    "    concepts_composes = re.findall(r'(\\w+-\\w+)', texte)\n",
    "\n",
    "    # get the doses and concepts_composes in one list\n",
    "    test = []\n",
    "    for dose in doses:\n",
    "        test.append(dose)\n",
    "    for concept in concepts_composes:\n",
    "        test.append(concept)\n",
    "\n",
    "    return test\n",
    "\n",
    "# Exemple\n",
    "words_conserved = conserve_important_words(texte_medical)\n",
    "print(words_conserved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce2eb6",
   "metadata": {},
   "source": [
    "# TOKENISATION DU TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920af094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens avant suppression des stopwords: ['Patient  admis le  pour coronavirus svre\\nCRP  N5 - Fivre  39.2C\\nTraitement par glucocorticoides intraveineux  azithromycine  \\nAttention allergie  la pnicilline']\n",
      "['Patient', 'admis', 'coronavirus', 'svre', 'CRP', 'N5', '-', 'Fivre', '39.2C', 'Traitement', 'glucocorticoides', 'intraveineux', 'azithromycine', 'Attention', 'allergie', 'pnicilline']\n"
     ]
    }
   ],
   "source": [
    "def supprimer_stopwords(mots):\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    # words = word_tokenize(text)\n",
    "    filtered_text = [word for word in mots if word not in stop_words]\n",
    "    return filtered_text\n",
    "def tokeniser_texte(texte):\n",
    "    # Tokenisation des phrases\n",
    "    phrases = sent_tokenize(texte, language='french')\n",
    "    \n",
    "    # Tokenisation des mots\n",
    "    tokens = [word_tokenize(phrase, language='french') for phrase in phrases]\n",
    "    \n",
    "    # Aplatir la liste de listes\n",
    "    tokens = [item for sublist in tokens for item in sublist]\n",
    "    \n",
    "    # Supprimer les stopwords\n",
    "    tokens = supprimer_stopwords(tokens)\n",
    "\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "tokenized_text = tokeniser_texte(texte_nettoye)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d5dc9",
   "metadata": {},
   "source": [
    "# NORMALISATION DU TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dfb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient', 'admis', 'coronavirus', 'svre', 'crp', 'n5', '-', 'fivr', '39.2c', 'trait', 'glucocorticoid', 'intravein', 'azithromycin', 'attent', 'allerg', 'pnicillin', ('125', 'mg', '/', 'L'), ('500', 'mg', '/', 'J'), ('125', 'mg'), ('500', 'mg'), ('500', 'mg'), 'COVID-19']\n"
     ]
    }
   ],
   "source": [
    "def normaliser_texte(words,words_conserved):\n",
    "    stemmer = SnowballStemmer(\"french\")\n",
    "    \n",
    "    # Flatten the list to handle tuples and strings\n",
    "    flattened_words = []\n",
    "    for word in words:\n",
    "        if isinstance(word, tuple):\n",
    "            flattened_words.extend(word)  # Add elements of the tuple\n",
    "        else:\n",
    "            flattened_words.append(word)  # Add the string directly\n",
    "\n",
    "    # Apply stemming only to strings\n",
    "    word_normalized = [stemmer.stem(word.lower()) for word in flattened_words if isinstance(word, str)]\n",
    "    \n",
    "    # Normaliser les termes médicaux\n",
    "    for terme, signification in terme_medicals.items():\n",
    "        word_normalized = [signification if word == terme.lower() else word for word in word_normalized]\n",
    "\n",
    "    # Normaliser les expressions composées\n",
    "    for expression, signification in expressions_composes.items():\n",
    "        word_normalized = [signification if word == expression.lower() else word for word in word_normalized]\n",
    "\n",
    "    # Normaliser les abréviations\n",
    "    for abrev, signification in abreviations.items():\n",
    "        word_normalized = [signification if word == abrev.lower() else word for word in word_normalized]\n",
    "\n",
    "    word_normalized += words_conserved\n",
    "    \n",
    "    return word_normalized\n",
    "\n",
    "# Exemple\n",
    "print(normaliser_texte(tokenized_text, words_conserved))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09070ff",
   "metadata": {},
   "source": [
    "# NEW EXEMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ff498",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"texte1\" : \"\"\"Pat. 60ans hospitalisé le 15/04/2023 pour pneumopathie.\n",
    "        CRP à 240mg/L. Ttt initial par amoxicilline 1g/J.\n",
    "        Fièvre persistante à 38.5°C. Scanner réalisé.\n",
    "        \"\"\",\n",
    "    \"texte2\" : \"\"\"Pat. 33ans. Chute le 01/01/25. Scanner cérébral normal.\n",
    "        Température à 37.8ºC. Ttt: paracétamol 500mg.\n",
    "        \"\"\",\n",
    "    \"texte3\" : \"\"\"Admission d’un homme de 72ans le 02/02/22.\n",
    "        Douleurs thoraciques. ECG normal. Troponine: 0.04ng/mL.\n",
    "        Ttt: surveillance + aspirine 75mg/j.\n",
    "        \"\"\",\n",
    "    \"texte4\" : \"\"\"Pat. 25ans, suivi pour asthme. Crise aiguë le 04/03/2025.\n",
    "        Oxygène à 3L/min. Corticoïdes 100mg IV administrés.\n",
    "        \"\"\",\n",
    "    \"texte5\" : \"\"\"Pat. 50ans diabétique. Consultation du 10/10/2020.\n",
    "        HbA1c: 9.2%. Ttt modifié: metformine 1000mg/j.\n",
    "        Régime conseillé. Poids: 95kg.\n",
    "        \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e93d4",
   "metadata": {},
   "source": [
    "## NETTOYER -> CONSERVER LES DOSES ET MOTS COMPOSÉ -> TOKENISER LE TEXT -> NORMALISER LE TEXT -> VISUALISER LES RESULTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91c17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texte1: Pat. 60ans hospitalisé le 15/04/2023 pour pneumopathie.\n",
      "        CRP à 240mg/L. Ttt initial par amoxicilline 1g/J.\n",
      "        Fièvre persistante à 38.5°C. Scanner réalisé.\n",
      "        \n",
      "Texte nettoyé: Patient  hospitalis le  pour pneumopathie\n",
      "        CRP   Traitement initial par amoxicilline \n",
      "        Fivre persistante  38.5C Scanner ralis\n",
      "Dose et Mots composé : [('240', 'mg', '/', 'L'), ('1', 'g', '/', 'J'), ('240', 'mg'), ('1', 'g')]\n",
      "Tokens avant suppression des stopwords: ['Patient  admis le  pour coronavirus svre\\nCRP  N5 - Fivre  39.2C\\nTraitement par glucocorticoides intraveineux  azithromycine  \\nAttention allergie  la pnicilline']\n",
      "Texte tokenisé: ['Patient', 'admis', 'coronavirus', 'svre', 'CRP', 'N5', '-', 'Fivre', '39.2C', 'Traitement', 'glucocorticoides', 'intraveineux', 'azithromycine', 'Attention', 'allergie', 'pnicilline']\n",
      "Text Normaliser : ['patient', 'admis', 'coronavirus', 'svre', 'crp', 'n5', '-', 'fivr', '39.2c', 'trait', 'glucocorticoid', 'intravein', 'azithromycin', 'attent', 'allerg', 'pnicillin', ('240', 'mg', '/', 'L'), ('1', 'g', '/', 'J'), ('240', 'mg'), ('1', 'g')]\n",
      "\n",
      "\n",
      "texte2: Pat. 33ans. Chute le 01/01/25. Scanner cérébral normal.\n",
      "        Température à 37.8ºC. Ttt: paracétamol 500mg.\n",
      "        \n",
      "Texte nettoyé: Patient  Chute le  Scanner crbral normal\n",
      "        Temprature  37.8C Traitement paractamol\n",
      "Dose et Mots composé : [('500', 'mg')]\n",
      "Tokens avant suppression des stopwords: ['Patient  admis le  pour coronavirus svre\\nCRP  N5 - Fivre  39.2C\\nTraitement par glucocorticoides intraveineux  azithromycine  \\nAttention allergie  la pnicilline']\n",
      "Texte tokenisé: ['Patient', 'admis', 'coronavirus', 'svre', 'CRP', 'N5', '-', 'Fivre', '39.2C', 'Traitement', 'glucocorticoides', 'intraveineux', 'azithromycine', 'Attention', 'allergie', 'pnicilline']\n",
      "Text Normaliser : ['patient', 'admis', 'coronavirus', 'svre', 'crp', 'n5', '-', 'fivr', '39.2c', 'trait', 'glucocorticoid', 'intravein', 'azithromycin', 'attent', 'allerg', 'pnicillin', ('500', 'mg')]\n",
      "\n",
      "\n",
      "texte3: Admission d’un homme de 72ans le 02/02/22.\n",
      "        Douleurs thoraciques. ECG normal. Troponine: 0.04ng/mL.\n",
      "        Ttt: surveillance + aspirine 75mg/j.\n",
      "        \n",
      "Texte nettoyé: Admission dun homme de  le \n",
      "        Douleurs thoraciques ECG normal Troponine \n",
      "        Traitement surveillance  aspirine\n",
      "Dose et Mots composé : [('75', 'mg', '/', 'j'), ('75', 'mg')]\n",
      "Tokens avant suppression des stopwords: ['Patient  admis le  pour coronavirus svre\\nCRP  N5 - Fivre  39.2C\\nTraitement par glucocorticoides intraveineux  azithromycine  \\nAttention allergie  la pnicilline']\n",
      "Texte tokenisé: ['Patient', 'admis', 'coronavirus', 'svre', 'CRP', 'N5', '-', 'Fivre', '39.2C', 'Traitement', 'glucocorticoides', 'intraveineux', 'azithromycine', 'Attention', 'allergie', 'pnicilline']\n",
      "Text Normaliser : ['patient', 'admis', 'coronavirus', 'svre', 'crp', 'n5', '-', 'fivr', '39.2c', 'trait', 'glucocorticoid', 'intravein', 'azithromycin', 'attent', 'allerg', 'pnicillin', ('75', 'mg', '/', 'j'), ('75', 'mg')]\n",
      "\n",
      "\n",
      "texte4: Pat. 25ans, suivi pour asthme. Crise aiguë le 04/03/2025.\n",
      "        Oxygène à 3L/min. Corticoïdes 100mg IV administrés.\n",
      "        \n",
      "Texte nettoyé: Patient , suivi pour asthme Crise aigu le \n",
      "        Oxygne   Corticodes  intraveineux administrs\n",
      "Dose et Mots composé : [('3', 'L', '/', 'min'), ('3', 'L'), ('100', 'mg')]\n",
      "Tokens avant suppression des stopwords: ['Patient  admis le  pour coronavirus svre\\nCRP  N5 - Fivre  39.2C\\nTraitement par glucocorticoides intraveineux  azithromycine  \\nAttention allergie  la pnicilline']\n",
      "Texte tokenisé: ['Patient', 'admis', 'coronavirus', 'svre', 'CRP', 'N5', '-', 'Fivre', '39.2C', 'Traitement', 'glucocorticoides', 'intraveineux', 'azithromycine', 'Attention', 'allergie', 'pnicilline']\n",
      "Text Normaliser : ['patient', 'admis', 'coronavirus', 'svre', 'crp', 'n5', '-', 'fivr', '39.2c', 'trait', 'glucocorticoid', 'intravein', 'azithromycin', 'attent', 'allerg', 'pnicillin', ('3', 'L', '/', 'min'), ('3', 'L'), ('100', 'mg')]\n",
      "\n",
      "\n",
      "texte5: Pat. 50ans diabétique. Consultation du 10/10/2020.\n",
      "        HbA1c: 9.2%. Ttt modifié: metformine 1000mg/j.\n",
      "        Régime conseillé. Poids: 95kg.\n",
      "        \n",
      "Texte nettoyé: Patient  diabtique Consultation du \n",
      "        HbA 9.2 Traitement modifi metformine \n",
      "        Rgime conseill Poids\n",
      "Dose et Mots composé : [('1000', 'mg', '/', 'j'), ('1000', 'mg')]\n",
      "Tokens avant suppression des stopwords: ['Patient  admis le  pour coronavirus svre\\nCRP  N5 - Fivre  39.2C\\nTraitement par glucocorticoides intraveineux  azithromycine  \\nAttention allergie  la pnicilline']\n",
      "Texte tokenisé: ['Patient', 'admis', 'coronavirus', 'svre', 'CRP', 'N5', '-', 'Fivre', '39.2C', 'Traitement', 'glucocorticoides', 'intraveineux', 'azithromycine', 'Attention', 'allergie', 'pnicilline']\n",
      "Text Normaliser : ['patient', 'admis', 'coronavirus', 'svre', 'crp', 'n5', '-', 'fivr', '39.2c', 'trait', 'glucocorticoid', 'intravein', 'azithromycin', 'attent', 'allerg', 'pnicillin', ('1000', 'mg', '/', 'j'), ('1000', 'mg')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    texte_nettoyes = nettoyer_texte(value)\n",
    "    print(\"Texte nettoyé:\", texte_nettoyes)\n",
    "    conserved_words = conserve_important_words(value)\n",
    "    print(\"Dose et Mots composé :\", conserved_words)\n",
    "    tokenized_text = tokeniser_texte(texte_nettoye)\n",
    "    print(\"Texte tokenisé:\", tokenized_text)\n",
    "    texte_normalise = normaliser_texte(tokenized_text,conserved_words)\n",
    "    print(\"Text Normaliser :\", texte_normalise)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
